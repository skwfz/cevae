import pandas as pd
import numpy as np
import math, random
import torch
import torch.distributions as dist
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from torch.utils.data.sampler import SubsetRandomSampler
from scipy import stats
import seaborn as sns

def binary_data_df(num_samples, 
                    z_expectation,
                    x_expectations,
                    t_expectations,
                    y_expectations) -> pd.DataFrame:
    """x_expectations is of dim (x vars)x(2). t_expectations is 1x2, y_expectations is 1x4.
    The columns correspond to different conditioning variable values, e.g. P(x=1|z=0) and P(x=1|z=1).
    """
    x_dim = x_expectations.shape[0]
    
    z_dist = dist.Bernoulli(probs=z_expectation)
    zs = z_dist.sample((num_samples,))
    
    #Column 0 corresponds to P(x=1|z=0) (multiple values) and column 1 to P(x=1|z=1)
    xs_0 = dist.Bernoulli(probs=x_expectations[:,0].T).sample((num_samples,))
    xs_1 = dist.Bernoulli(probs=x_expectations[:,1].T).sample((num_samples,))
    xs = torch.where(zs==1,xs_1,xs_0)
    print(xs.size())
    
    #Column 0 corresponds to P(t=1|z=0) and column 1 to P(t=1|z=1)
    ts_0 = dist.Bernoulli(probs=t_expectations[:,0]).sample((num_samples,))
    ts_1 = dist.Bernoulli(probs=t_expectations[:,1]).sample((num_samples,))
    ts = torch.where(zs==1,ts_1,ts_0)
    
    #Combinations (z=0,t=0), (z=0,t=1), (z=1,t=0), (z=1,t=1). 
    #Columns of y_expectations are in that order e.g. P(y=1|z=0,t=0)
    yf_00 = dist.Bernoulli(probs=y_expectations[:,0]).sample((num_samples,))
    yf_01 = dist.Bernoulli(probs=y_expectations[:,1]).sample((num_samples,))
    yf_10 = dist.Bernoulli(probs=y_expectations[:,2]).sample((num_samples,))
    yf_11 = dist.Bernoulli(probs=y_expectations[:,3]).sample((num_samples,))
    #Actual outcomes
    yf = torch.zeros((num_samples,1))
    yf[(zs==0) & (ts==0)] = yf_00[(zs==0) & (ts==0)]
    yf[(zs==0) & (ts==1)] = yf_01[(zs==0) & (ts==1)]
    yf[(zs==1) & (ts==0)] = yf_10[(zs==1) & (ts==0)]
    yf[(zs==1) & (ts==1)] = yf_11[(zs==1) & (ts==1)]
    #Counterfactuals
    y0 = torch.zeros((num_samples,1))
    y0[(zs==0)] = yf_00[(zs==0)]
    y0[(zs==1)] = yf_10[(zs==1)]
    y1 = torch.zeros((num_samples,1))
    y1[(zs==0)] = yf_01[(zs==0)]
    y1[(zs==1)] = yf_11[(zs==1)]
    
    df = pd.DataFrame(torch.cat([zs,xs,ts,yf,y0,y1], axis=1).numpy(), columns=['z'] + ['x{}'.format(i) for i in range(x_dim)] + ['t','yf','y0','y1'])
    
    return df

# Define pytorch datasets and loaders
class BinaryDataset(Dataset):
    def __init__(self, data: pd.DataFrame):
        self.length = data.shape[0]
        x_dim = data.shape[1]-5#minus z,t,yf,y0 and y1
        self.t = data.loc[:, ['t']].values
        self.X = data.iloc[:, 1:1+x_dim].values#Assumes that the dataframe is generated by binary_data_df
        self.y0 = data.loc[:, ['y0']].values
        self.y1 = data.loc[:, ['y1']].values
        self.yf = data.loc[:, ['yf']].values

    def __getitem__(self, idx):
        return {
            'X': self.X[idx],
            't': self.t[idx],
            'y0': self.y0[idx],
            'y1': self.y1[idx],
            'yf': self.yf[idx]
        }

    def __len__(self):
        return self.length

class BinaryDataLoader(DataLoader):
    def __init__(self, dataset, validation_split=0.2, shuffle=True):
        dataset_size = len(dataset)
        indices = list(range(dataset_size))
        split = int(np.floor(validation_split * dataset_size))
        if shuffle:
            np.random.shuffle(indices)
        train_indices, valid_indices = indices[split:], indices[: split]

        self.dataset = dataset
        self.train_sampler = SubsetRandomSampler(train_indices)
        self.valid_sampler = SubsetRandomSampler(valid_indices)

    def collate_fn(self, batch):
        keys = list(batch[0].keys())
        processed_batch = {k: [] for k in keys}
        for _, sample in enumerate(batch):
            for key, value in sample.items():
                processed_batch[key].append(value)
        
        processed_batch['t'] = torch.FloatTensor(processed_batch['t'])
        processed_batch['X'] = torch.FloatTensor(processed_batch['X'])
        processed_batch['y0'] = torch.FloatTensor(processed_batch['y0'])
        processed_batch['y1'] = torch.FloatTensor(processed_batch['y1'])
        processed_batch['yf'] = torch.FloatTensor(processed_batch['yf'])
        return processed_batch

    def train_loader(self, batch_size, num_workers=0):
        train_loader = DataLoader(
            dataset=self.dataset,
            batch_size=batch_size,
            collate_fn=self.collate_fn,
            sampler=self.train_sampler,
            num_workers=num_workers,
            pin_memory=True,
            drop_last=True
        )

        return train_loader

    def test_loader(self, batch_size, num_workers=0):
        test_loader = DataLoader(
            dataset=self.dataset,
            batch_size=batch_size,
            collate_fn=self.collate_fn,
            sampler=self.valid_sampler,
            num_workers=num_workers,
            pin_memory=True,
            shuffle=False,
            drop_last=True
        )

        return test_loader

    def get_loaders(self, batch_size):
        train_loader = self.train_loader(batch_size)
        test_loader = self.test_loader(batch_size)

        return train_loader, test_loader