{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from binarytoydata import *\n",
    "from dummymodels import *\n",
    "%load_ext autoreload\n",
    "import pandas as pd\n",
    "import torch.distributions as dist\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import itertools\n",
    "from binary_data_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 2])\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10000\n",
    "z_expectation = torch.Tensor([0.5])\n",
    "x_expectations = torch.Tensor([[0.1,0.9],\n",
    "                              [0.9,0.1]])\n",
    "x_dim = len(x_expectations)\n",
    "t_expectations = torch.Tensor([[0.9,0.1]])\n",
    "y_expectations = torch.Tensor([[0.1,0.8,0.2,0.95]])\n",
    "df = binary_data_df(num_samples, z_expectation, x_expectations, t_expectations, y_expectations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get the convenience function and define the corresponding dataframe\"\"\"\n",
    "calculate_prob = generate_calculate_prob(z_expectation, x_expectations, t_expectations, y_expectations)\n",
    "prob_df = pd.DataFrame([c + (calculate_prob(c[0], c[1:3], c[3], c[4]),) for c in itertools.product([0,1],repeat=5)], \n",
    "                       columns=['z'] + ['x{}'.format(i) for i in range(x_dim)] + ['t', 'yf', 'P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True and proxy based ATEs: 0.725, 0.697\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Calculating the true ATE and the ATE we get by adjusting just for the proxies\"\"\"\n",
    "print(\"True and proxy based ATEs: {:.3f}, {:.3f}\".format(calculate_true_ate(prob_df), \n",
    "    calculate_proxy_ate(prob_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Functions that do P(y=1|X,t) and P(y=1|t) predictions perfectly\"\"\"\n",
    "%autoreload 2\n",
    "p_y_xt_f = generate_p_y_xt(prob_df)\n",
    "p_t_x_f = generate_p_t_x(prob_df)\n",
    "q_y_xt_f = generate_q_y_xt(df)\n",
    "q_t_x_f = generate_q_t_x(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(df[['x0','x1']].values)\n",
    "p_y_xt_f(x[0][0].item(),x[0][1].item(),1) \n",
    "model_ITE = modelITE(model, x, p_y_xt_f, p_t_x_f)\n",
    "proxy_ITE = proxyITE(x, q_y_xt_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6946)\n",
      "tensor(0.7366, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(proxy_ITE.mean())\n",
    "print(model_ITE.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7211, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_sample2 = dist.Bernoulli(torch.Tensor([0.5])).sample((10000,))\n",
    "p_y_do1_model = torch.sigmoid(model.decoder.y1_nn(z_sample2)).mean()\n",
    "p_y_do0_model =torch.sigmoid(model.decoder.y0_nn(z_sample2)).mean()\n",
    "ate = p_y_do1_model - p_y_do0_model\n",
    "ate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run this before the first time running the next cell\"\"\"\n",
    "i = 0\n",
    "j = 0\n",
    "dfs = [[0 for j in range(10)] for i in range(len(datasizes))]\n",
    "models = [[0 for j in range(10)] for i in range(len(datasizes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size 1000, run 1\n",
      "Estimated ATE: 0.6306077241897583\n",
      "Training data size 1000, run 2\n",
      "Estimated ATE: 0.717467725276947\n",
      "Training data size 1000, run 3\n",
      "Estimated ATE: 0.6892865896224976\n",
      "Training data size 1000, run 4\n",
      "Estimated ATE: 0.7410643100738525\n",
      "Training data size 1000, run 5\n",
      "Estimated ATE: 0.6351633071899414\n",
      "Training data size 1000, run 6\n",
      "Estimated ATE: 0.6556169986724854\n",
      "Training data size 1000, run 7\n",
      "Estimated ATE: 0.5494042634963989\n",
      "Training data size 1000, run 8\n",
      "Estimated ATE: 0.7219117283821106\n",
      "Training data size 1000, run 9\n",
      "Estimated ATE: 0.6021299362182617\n",
      "Training data size 1000, run 10\n",
      "Estimated ATE: 0.6953056454658508\n",
      "Training data size 2000, run 1\n",
      "Estimated ATE: 0.7228432893753052\n",
      "Training data size 2000, run 2\n",
      "Estimated ATE: 0.6149059534072876\n",
      "Training data size 2000, run 3\n",
      "Estimated ATE: 0.7589566111564636\n",
      "Training data size 2000, run 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Runs the model for different datasets multiple times\"\"\"\n",
    "BATCH_SIZE = 1000\n",
    "datasize_times = 10\n",
    "device = 'cpu'\n",
    "datasizes = [1000,2000,6000,10000,15000]\n",
    "#what results are we gathering?\n",
    "\n",
    "#Simulating datasets and training models\n",
    "while i < len(datasizes):\n",
    "    #dfs.append([])\n",
    "    #models.append([])\n",
    "    while j < datasize_times:\n",
    "        num_samples = datasizes[i]\n",
    "        print(\"Training data size {}, run {}\".format(num_samples, j+1))\n",
    "        df = binary_data_df(num_samples, z_expectation, x_expectations, t_expectations, y_expectations)\n",
    "        dataset = BinaryDataset(df)\n",
    "        dataloader = BinaryDataLoader(dataset, validation_split=0.0)\n",
    "        train_loader, test_loader = dataloader.get_loaders(batch_size=BATCH_SIZE)\n",
    "        #dummy test loader\n",
    "        test_loader, _ = BinaryDataLoader(BinaryDataset(df[:1]), validation_split=0.0).get_loaders(batch_size=1)\n",
    "        #Running the model\n",
    "        model = run_cevae(num_epochs=200, lr_start=0.3, lr_end=0.01,\n",
    "                train_loader=train_loader, test_loader=test_loader, input_dim=2,\n",
    "                plot_curves=False, print_logs=False)\n",
    "    \n",
    "        dfs[i][j] = df\n",
    "        models[i][j] = model\n",
    "        \n",
    "        torch.save(model.state_dict(), \"./dummy_data/model{}_{}\".format(num_samples,j))\n",
    "        df.to_pickle(\"./dummy_data/data{}_{}\".format(num_samples,j))\n",
    "        \n",
    "        x = torch.Tensor(df[['x0','x1']].values)\n",
    "        print(\"Estimated ATE: {}\".format(modelITE(model, x, p_y_xt_f, p_t_x_f).mean()))\n",
    "        \n",
    "        j += 1\n",
    "    j = 0\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating results from the models\n",
    "model_ITEs_1 = [[] for n in range(len(datasizes))]\n",
    "model_ITEs_2 = [[] for n in range(len(datasizes))]\n",
    "model_ATEs_1 = [[] for n in range(len(datasizes))]\n",
    "model_ATEs_2 = [[] for n in range(len(datasizes))]\n",
    "model_ATEs_3 = [[] for n in range(len(datasizes))]\n",
    "proxy_ITEs = [[] for n in range(len(datasizes))]\n",
    "proxy_ATEs = [[] for n in range(len(datasizes))]\n",
    "dists_VAE = [[] for n in range(len(datasizes))]\n",
    "dists_data = [[] for n in range(len(datasizes))]\n",
    "dists_true = [[] for n in range(len(datasizes))]\n",
    "\n",
    "for n in range(len(datasizes)):\n",
    "    for i in range(datasize_times):\n",
    "        #P(y=1|X,t) and P(t=1|X) estimates directly from the data\n",
    "        df = dfs[n][i]\n",
    "        model = models[n][i]\n",
    "        q_y_xt_f = generate_q_y_xt(df)\n",
    "        q_t_x_f = generate_q_t_x(df)\n",
    "\n",
    "        #Getting the ITE and ATE estimates\n",
    "        x = torch.Tensor(df[['x0','x1']].values)\n",
    "        p_y_xt_f(x[0][0].item(),x[0][1].item(),1)\n",
    "        model_ITEs_1[n].append(modelITE(model, x, p_y_xt_f, p_t_x_f))\n",
    "        model_ITEs_2[n].append(modelITE(model, x, q_y_xt_f, q_t_x_f))\n",
    "        proxy_ITEs.append(proxyITE(x, q_y_xt_f))\n",
    "        model_ATEs_1[n].append(model_ITE_1.mean())\n",
    "        model_ATEs_2[n].append(model_ITE_2.mean())\n",
    "        proxy_ATEs[n].append(proxy_ATE.mean())\n",
    "        z_sample = dist.Bernoulli(torch.Tensor([0.5])).sample((50000,))\n",
    "        p_y_do1_model = torch.sigmoid(model.decoder.y1_nn(z_sample)).mean()\n",
    "        p_y_do0_model =torch.sigmoid(model.decoder.y0_nn(z_sample)).mean()\n",
    "        model_ATEs_3[n].append(p_y_do1_model - p_y_do0_model)\n",
    "\n",
    "        #Getting probability distribution estimates\n",
    "        zs, xs, ts, ys = model.decoder.sample(50000)\n",
    "        sample_data = torch.cat([xs,ts,ys],axis=1)\n",
    "        dist_VAE, dist_data, dist_true = getJointDistributions(sample_data, df[['x0','x1','t','yf']],prob_df)\n",
    "        dists_VAE[n].append(dists_VAE)\n",
    "        dists_data[n].append(dists_data)\n",
    "        dists_true[n].append(dists_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "BATCH_SIZE = 1000\n",
    "device = 'cpu'\n",
    "dataset = BinaryDataset(df)\n",
    "dataloader = BinaryDataLoader(dataset, validation_split=0.0)\n",
    "train_loader, test_loader = dataloader.get_loaders(batch_size=BATCH_SIZE)\n",
    "#dummy test loader\n",
    "test_loader, _ = BinaryDataLoader(BinaryDataset(df[:1]), validation_split=0.0).get_loaders(batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = run_cevae(num_epochs=200, lr_start=0.3, lr_end=0.01,\n",
    "                  train_loader=train_loader, test_loader=test_loader, input_dim=2,\n",
    "                 plot_curves=True, print_logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "zs, xs, ts, ys = model.decoder.sample(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marginal probs according to VAE and according to the data\n",
      "P(x0=0,x1=0,t=0,yf=0)\t0.0375(VAE)\t=0.0389(data)\t0.0365(true)\n",
      "P(x0=0,x1=0,t=0,yf=1)\t0.00935(VAE)\t=0.0067(data)\t0.0086(true)\n",
      "P(x0=0,x1=0,t=1,yf=0)\t0.00905(VAE)\t=0.0085(data)\t0.0083(true)\n",
      "P(x0=0,x1=0,t=1,yf=1)\t0.03555(VAE)\t=0.0355(data)\t0.0367(true)\n",
      "P(x0=0,x1=1,t=0,yf=0)\t0.03695(VAE)\t=0.0402(data)\t0.0401(true)\n",
      "P(x0=0,x1=1,t=0,yf=1)\t0.0067(VAE)\t=0.0052(data)\t0.0050(true)\n",
      "P(x0=0,x1=1,t=1,yf=0)\t0.06975(VAE)\t=0.0703(data)\t0.0729(true)\n",
      "P(x0=0,x1=1,t=1,yf=1)\t0.29225(VAE)\t=0.2937(data)\t0.2921(true)\n",
      "P(x0=1,x1=0,t=0,yf=0)\t0.29475(VAE)\t=0.291(data)\t0.2920(true)\n",
      "P(x0=1,x1=0,t=0,yf=1)\t0.0738(VAE)\t=0.0733(data)\t0.0729(true)\n",
      "P(x0=1,x1=0,t=1,yf=0)\t0.00415(VAE)\t=0.0031(data)\t0.0029(true)\n",
      "P(x0=1,x1=0,t=1,yf=1)\t0.03415(VAE)\t=0.036(data)\t0.0421(true)\n",
      "P(x0=1,x1=1,t=0,yf=0)\t0.03745(VAE)\t=0.039(data)\t0.0364(true)\n",
      "P(x0=1,x1=1,t=0,yf=1)\t0.0099(VAE)\t=0.0092(data)\t0.0085(true)\n",
      "P(x0=1,x1=1,t=1,yf=0)\t0.00835(VAE)\t=0.0087(data)\t0.0083(true)\n",
      "P(x0=1,x1=1,t=1,yf=1)\t0.04035(VAE)\t=0.0407(data)\t0.0367(true)\n",
      "P(t=0,yf=0)\t0.40665(VAE)\t=0.4091(data)\t0.4050(true)\n",
      "P(t=0,yf=1)\t0.09975(VAE)\t=0.0944(data)\t0.0950(true)\n",
      "P(t=1,yf=0)\t0.0913(VAE)\t=0.0906(data)\t0.0925(true)\n",
      "P(t=1,yf=1)\t0.4023(VAE)\t=0.4059(data)\t0.4075(true)\n",
      "P(t=0,yf=0,z=0)\t0.04145(VAE)\t=0.0463(data)\t0.0450(true)\n",
      "P(t=0,yf=0,z=1)\t0.3652(VAE)\t=0.3628(data)\t0.3600(true)\n",
      "P(t=0,yf=1,z=0)\t0.0078(VAE)\t=0.0058(data)\t0.0050(true)\n",
      "P(t=0,yf=1,z=1)\t0.09195(VAE)\t=0.0886(data)\t0.0900(true)\n",
      "P(t=1,yf=0,z=0)\t0.08685(VAE)\t=0.088(data)\t0.0900(true)\n",
      "P(t=1,yf=0,z=1)\t0.00445(VAE)\t=0.0026(data)\t0.0025(true)\n",
      "P(t=1,yf=1,z=0)\t0.36355(VAE)\t=0.3639(data)\t0.3600(true)\n",
      "P(t=1,yf=1,z=1)\t0.03875(VAE)\t=0.042(data)\t0.0475(true)\n"
     ]
    }
   ],
   "source": [
    "print(\"Marginal probs according to VAE and according to the data\")\n",
    "\n",
    "sample_data = torch.cat([xs,ts,ys],axis=1)\n",
    "printCombinations(sample_data, df[['x0','x1','t','yf']],prob_df)\n",
    "\n",
    "sample_data = torch.cat([ts,ys],axis=1)\n",
    "printCombinations(sample_data, df[['t','yf']],prob_df)\n",
    "\n",
    "sample_data = torch.cat([ts,ys,zs],axis=1)\n",
    "printCombinations(sample_data, df[['t','yf','z']],prob_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = torch.cat([xs,ts,ys,zs],axis=1)\n",
    "printCombinations(sample_data, df[['x0','x1','t','yf','z']])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
